{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements stacked ensemble using 7 meta learner models and 1 super learner model. Gradient Boost and Naive Bayes have also been used to classify phishing emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import Modules</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,auc,roc_curve, confusion_matrix\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn import tree\n",
    "from scipy.sparse import hstack, vstack, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>User defined functions for data pre-processing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_urls(string):\n",
    "    regex_2 = r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\"\n",
    "    regex_3 = r\"(http|ftp|https): / / ([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\"\n",
    "    url = []\n",
    "    try:\n",
    "        url_2 = re.findall(regex_2, string)\n",
    "        url_second = [x for element in url_2 for x in element if x !=\"\"]\n",
    "        url_3 = re.findall(regex_3, string)\n",
    "        url_third = [x for element in url_3 for x in element if x !=\"\"]\n",
    "        url = url_second + url_third\n",
    "    except:\n",
    "        print(\"error\")\n",
    "    finally:\n",
    "        return url\n",
    "\n",
    "def count_urls(url_list):\n",
    "    num=0\n",
    "    for url in url_list:\n",
    "        num = num + len(url)\n",
    "    return num\n",
    "\n",
    "def text_url_similarity(text):\n",
    "    url_list = list_urls(text)\n",
    "    new_text = text\n",
    "    count = 0\n",
    "    for url in url_list:\n",
    "        # print(url)\n",
    "        if url != \"\":\n",
    "            if url in text:\n",
    "                try:\n",
    "                    new_text = re.sub(url, \"\", new_text)\n",
    "                except:\n",
    "                    count = count + 1\n",
    "    words = nltk.word_tokenize(new_text)\n",
    "    sim = 0\n",
    "    try:\n",
    "        sim = max([similar(url, word) for word in words for url in url_list])\n",
    "    except:\n",
    "        sim = 0\n",
    "    return sim\n",
    "\n",
    "def domain_url_similarity(domain, text):\n",
    "    url_list = list_urls(text)\n",
    "    sim = 0\n",
    "    try:\n",
    "        sim = max([similar(url, domain) for url in url_list])\n",
    "    except:\n",
    "        sim = 0\n",
    "    return sim\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string\n",
    "\n",
    "def similar(a, b):\n",
    "    if isNaN(a) | isNaN(b):\n",
    "        return 0\n",
    "    else:\n",
    "        return SequenceMatcher(None, a, b).ratio()\n",
    "    \n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression(max_iter=300))\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(MultinomialNB())\n",
    "#     models.append(KNeighborsClassifier())\n",
    "    models.append(AdaBoostClassifier())\n",
    "    models.append(BaggingClassifier(n_estimators=10))\n",
    "    models.append(RandomForestClassifier(n_estimators=10))\n",
    "    models.append(ExtraTreesClassifier(n_estimators=10))\n",
    "    return models\n",
    "\n",
    "def get_out_of_fold_predictions(X, y, models, sparse=False):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    # define split of data\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X):\n",
    "        fold_yhats = list()\n",
    "        # get data\n",
    "        train_X, text_X, train_y, test_y = list(),list(),list(),list()\n",
    "        if sparse:\n",
    "            train_X, test_X = X[list(train_ix)], X[list(test_ix)]\n",
    "            train_y, test_y = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        else:\n",
    "            train_X, test_X = X.iloc[list(train_ix)], X.iloc[list(test_ix)]\n",
    "            train_y, test_y = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        \n",
    "        meta_y.extend(test_y)\n",
    "        # fit and make predictions with each sub-model\n",
    "        for model in models:\n",
    "            model.fit(train_X, train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            # store columns\n",
    "            fold_yhats.append(list(yhat))\n",
    "\n",
    "        # store fold yhats as columns\n",
    "        arr_fold_yhats = np.array(fold_yhats)\n",
    "        meta_X.append(hstack(blocks=[csr_matrix(arr_fold_yhats.T)]))\n",
    "    \n",
    "    return vstack(meta_X), np.array(meta_y)\n",
    "\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "\n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "########## Gradient Boosting ############\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "########## SVM ############\n",
    "#     model = SVC()\n",
    "#     svm = LinearSVC()\n",
    "#     model = CalibratedClassifierCV(svm) \n",
    "#     model.fit(X, y)\n",
    "#     return model\n",
    "\n",
    "def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        model_acc = accuracy_score(y, yhat)\n",
    "        print('%s: Accuracy - %.3f' % (model.__class__.__name__, model_acc))\n",
    "        print(\"\\tTrain Accuracy : \",model.score(X,y))\n",
    "        print(\"\\tVal Accuracy : \",model.score(x_val,y_val))\n",
    "        \n",
    "def super_learner_predictions(X, models, meta_model):\n",
    "    meta_X = list()\n",
    "    yhat_models = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        yhat_models.append(list(yhat))\n",
    "    arr_yhat_models = np.array(yhat_models)\n",
    "    meta_X = hstack(blocks=[csr_matrix(arr_yhat_models.T)])\n",
    "    return meta_model.predict(meta_X), meta_model.predict_proba(meta_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read Data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Phishing Emails Dataset 1 from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv('fraud_email_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read phishing Emails Dataset 2 from CCAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac_mails = pd.read_excel('CCAC_data.xlsx')\n",
    "ccac_mails[\"Text\"] = ccac_mails[\"Subject\"].astype(str) + \" \" + ccac_mails[\"Body\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supply Quality China's EXCLUSIVE dimensions at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over. SidLet me know. Thx.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Friend,Greetings to you.I wish to accost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a surprising assessment from Embassy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Class\n",
       "0  Supply Quality China's EXCLUSIVE dimensions at...      1\n",
       "1                         over. SidLet me know. Thx.      0\n",
       "2  Dear Friend,Greetings to you.I wish to accost ...      1\n",
       "3  MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....      1\n",
       "4          Not a surprising assessment from Embassy.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign Email To randomly for kaggle dataset from ccac dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "emails[\"EmailTo\"] = random.choices(list(ccac_mails[ccac_mails[\"EmailTo\"].notnull()][\"EmailTo\"]), k=len(emails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 10% EmailTo as NA for Kaggle Dataset to match with CCAC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "indices = list(emails.index)\n",
    "length = len(emails)\n",
    "num = int(0.1*length)\n",
    "idx_replace = random.choices(indices, k=num)\n",
    "\n",
    "emails.loc[idx_replace, 'EmailTo'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 50% phishing emails with EmailTo as NA for Kaggle Dataset to match with CCAC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "indices = list(emails.loc[emails[\"Class\"]==1].index)\n",
    "length = len(emails[emails[\"Class\"]==1])\n",
    "num = int(0.5*length)\n",
    "idx_replace = random.choices(indices, k=num)\n",
    "\n",
    "emails.loc[idx_replace, 'EmailTo'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From CCAC data, get sender and sender's email address, and assign to Kaggle dataset with phishing emails as lower similarity and non phishing as higher similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "senders = ccac_mails[\"SenderName\"]\n",
    "senderEmails = ccac_mails[\"SenderEmailAddress\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "similarity_scores=np.zeros((len(senders),len(senderEmails)))\n",
    "for i in range(len(senders)):\n",
    "    similarity_scores[i][i] = similar(senders[i],senderEmails[i])\n",
    "    \n",
    "good_similarity_indices = np.where(similarity_scores>0.2)\n",
    "bad_similarity_indices = np.where((similarity_scores<0.2) & (similarity_scores!=0))\n",
    "\n",
    "idx_good_replace = random.choices(good_similarity_indices[0], k=10)\n",
    "idx_bad_replace = random.choice(bad_similarity_indices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "emails[\"SenderName\"] = random.choices(list(ccac_mails[ccac_mails[\"SenderName\"].notnull()][\"SenderName\"]), k=len(emails))\n",
    "emails[\"SenderEmailAddress\"] = random.choices(list(ccac_mails[ccac_mails[\"SenderEmailAddress\"].notnull()][\"SenderEmailAddress\"]), k=len(emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mail_indices = list(emails.index)\n",
    "length = len(emails)\n",
    "# num = int(0.1*length)\n",
    "\n",
    "for i in mail_indices:\n",
    "    idx_replace = random.choice(good_similarity_indices[0])\n",
    "    senders = list(ccac_mails.loc[idx_replace,[\"SenderName\",\"SenderEmailAddress\"]])\n",
    "    emails.loc[i, 'SenderName'] = senders[0]\n",
    "    emails.loc[i, 'SenderEmailAddress'] = senders[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "indices = list(emails.loc[emails[\"Class\"]==1].index)\n",
    "length = len(emails[emails[\"Class\"]==1])\n",
    "num = int(0.5*length)\n",
    "replace_indices = random.sample(indices, num)\n",
    "for i in replace_indices:\n",
    "    idx_replace = random.choice(bad_similarity_indices[0])\n",
    "    senders = list(ccac_mails.loc[idx_replace,[\"SenderName\",\"SenderEmailAddress\"]])\n",
    "    emails.loc[i, 'SenderName'] = senders[0]\n",
    "    emails.loc[i, 'SenderEmailAddress'] = senders[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pre-process</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword counts for phishing keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assistant_words = [\"personal assistant\", \"administrative assistant\"]\n",
    "assistant_ind =[any(x in str(ccac_mails[\"Text\"][i]).lower() for x in assistant_words) for i in range(len(ccac_mails))]\n",
    "assist_flag_mails = ccac_mails.loc[assistant_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "piano_words = [\"loving home\"]\n",
    "piano_ind =[any(x in str(ccac_mails[\"Text\"][i]).lower() for x in piano_words) for i in range(len(ccac_mails))]\n",
    "piano_flag_mails = ccac_mails.loc[piano_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "payment_words = [\"$50/hr\",\"$45/hr\",\"$40/hr\",\"$35/hr\",\"$30/hr\",\"$25/hr\",\"$20/hr\",\"$400 weekly\",\"$350 per week\",\"$350 weekly\",\"$300 weekly\",\"$250 weekly\"]\n",
    "payment_flag_ind =[any(x in str(ccac_mails[\"Text\"][i]) for x in payment_words) for i in range(len(ccac_mails))]\n",
    "payment_flag_mails = ccac_mails[payment_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "staff_words = [\"Dear Employee And Staff\", \"verify your account\",\"received a new message\",\"@ccac sales\",\"versions of our mailbox\",\"moonfruit.com\"]\n",
    "staff_flag_ind =[any(x in str(ccac_mails[\"Text\"][i]) for x in staff_words) for i in range(len(ccac_mails))]\n",
    "staff_flag_mails = ccac_mails[staff_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ad_words = [\"walmart\",\"reward\"]\n",
    "ad_flag_ind =[all(x in str(ccac_mails[\"Text\"][i]).lower() for x in ad_words) for i in range(len(ccac_mails))]\n",
    "ad_flag_mails = ccac_mails[ad_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac_sender_words = [\"@ccac sales\"]\n",
    "ccac_sender_flag_ind =[any(x in str(ccac_mails[\"SenderEmailAddress\"][i]).lower() for x in ccac_sender_words) for i in range(len(ccac_mails))]\n",
    "ccac_sender_flag_mails = ccac_mails[ccac_sender_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "subject_words = [\"APPLY NOW!!!\"]\n",
    "subject_flag_ind =[any(x in str(ccac_mails[\"Subject\"][i]) for x in subject_words) for i in range(len(ccac_mails))]\n",
    "subject_flag_mails = ccac_mails[subject_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "food_words = [\"food\"]\n",
    "food_flag_ind =[any(x in str(ccac_mails[\"Text\"][i]).lower() for x in food_words) for i in range(len(ccac_mails))]\n",
    "food_flag_mails = ccac_mails[food_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phish_ccac = assist_flag_mails.merge(piano_flag_mails, how=\"outer\").merge(payment_flag_mails, how=\"outer\").merge(staff_flag_mails, how=\"outer\").merge(ad_flag_mails, how=\"outer\").merge(ccac_sender_flag_mails, how=\"outer\").merge(subject_flag_mails, how=\"outer\").merge(food_flag_mails, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "phish_ccac[\"Class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phish_ccac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword counts for Non phishing mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "meeting_words = [\"microsoft teams meeting\",\"zoom.us\",\"webex.com\", \"teams.microsoft.com\", \"join zoom meeting\",\"do not delete or change\", \"gartner.com\"]\n",
    "teams_mails_ind =[any(x in str(ccac_mails[\"Body\"][i]).lower() for x in meeting_words) for i in range(len(ccac_mails))]\n",
    "teams_mails = ccac_mails[teams_mails_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "subject_words = [\"accepted\",\"canceled\",\"declined\",\"tentative\",\"reminder\",\"confirmation\",\"1 on 1\",\"hold\"]\n",
    "subject_flag_ind =[any(x in str(ccac_mails[\"Subject\"][i]).lower() for x in subject_words) for i in range(len(ccac_mails))]\n",
    "sub_flag_mails = ccac_mails[subject_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "what_words = [\"b6b3845926249a034f20cb8c4e628562\"]\n",
    "what_flag_ind =[any(x in str(ccac_mails[\"Text\"][i]).lower() for x in what_words) for i in range(len(ccac_mails))]\n",
    "what_flag_mails = ccac_mails[what_flag_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1620\n",
      "267\n",
      "664\n"
     ]
    }
   ],
   "source": [
    "print(len(teams_mails))\n",
    "print(len(food_flag_mails))\n",
    "print(len(sub_flag_mails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "nonphish_ccac = teams_mails.merge(sub_flag_mails, how=\"outer\")#.drop(columns=[\"Id\",\"CC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "nonphish_ccac[\"Class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>EmailTo</th>\n",
       "      <th>CC</th>\n",
       "      <th>SenderName</th>\n",
       "      <th>SenderEmailAddress</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Babur Rais Abolt; Brandon Aristeo Akcali; Osam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suchit Abdullah</td>\n",
       "      <td>AbdullahSuc1912@ccac.sales.com</td>\n",
       "      <td>Canceled: UUDEX Discussion</td>\n",
       "      <td>_________________________________________...</td>\n",
       "      <td>Canceled: UUDEX Discussion      ______________...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Hamad A Aivalotis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Aristeo Akcali</td>\n",
       "      <td>AkcaliBra3136@ccac.sales.com</td>\n",
       "      <td>check in with Hannah</td>\n",
       "      <td>_______________________________...</td>\n",
       "      <td>check in with Hannah                __________...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                            EmailTo  CC  \\\n",
       "0   3  Babur Rais Abolt; Brandon Aristeo Akcali; Osam... NaN   \n",
       "1   4                                  Hamad A Aivalotis NaN   \n",
       "\n",
       "               SenderName              SenderEmailAddress  \\\n",
       "0         Suchit Abdullah  AbdullahSuc1912@ccac.sales.com   \n",
       "1  Brandon Aristeo Akcali    AkcaliBra3136@ccac.sales.com   \n",
       "\n",
       "                      Subject  \\\n",
       "0  Canceled: UUDEX Discussion   \n",
       "1        check in with Hannah   \n",
       "\n",
       "                                                Body  \\\n",
       "0       _________________________________________...   \n",
       "1                 _______________________________...   \n",
       "\n",
       "                                                Text  Class  \n",
       "0  Canceled: UUDEX Discussion      ______________...      0  \n",
       "1  check in with Hannah                __________...      0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonphish_ccac.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonphish_ccac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac = phish_ccac.merge(nonphish_ccac, how=\"outer\").drop(columns=['Id', 'CC', 'Subject','Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2605\n"
     ]
    }
   ],
   "source": [
    "print(len(ccac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>EmailTo</th>\n",
       "      <th>SenderName</th>\n",
       "      <th>SenderEmailAddress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supply Quality China's EXCLUSIVE dimensions at...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisa Renee Agresta</td>\n",
       "      <td>AgrestaLis3731@ccac.sales.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over. SidLet me know. Thx.</td>\n",
       "      <td>0</td>\n",
       "      <td>James Akkiris</td>\n",
       "      <td>Brandon Aristeo Akcali</td>\n",
       "      <td>AkcaliBra3136@ccac.sales.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Class        EmailTo  \\\n",
       "0  Supply Quality China's EXCLUSIVE dimensions at...      1            NaN   \n",
       "1                         over. SidLet me know. Thx.      0  James Akkiris   \n",
       "\n",
       "               SenderName             SenderEmailAddress  \n",
       "0      Lisa Renee Agresta  AgrestaLis3731@ccac.sales.com  \n",
       "1  Brandon Aristeo Akcali   AkcaliBra3136@ccac.sales.com  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(2)\n",
    "# ccac.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "merged_emails = ccac.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "merged_emails = merged_emails[merged_emails[\"Text\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get valid domains from sender's email address from merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "domainList=[]\n",
    "for mail in merged_emails[\"SenderEmailAddress\"]:\n",
    "    try:\n",
    "        if '@' in mail:\n",
    "            spl = mail.split('@')\n",
    "            if len(spl) > 1:\n",
    "                domainList.append(spl[1])\n",
    "            else:\n",
    "                domainList.append(\"na\")\n",
    "        else:\n",
    "            domainList.append(\"na\")\n",
    "    except:\n",
    "        domainList.append(\"na\")\n",
    "\n",
    "merged_emails[\"domain\"] = domainList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Sender name and email similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "name_email_sim=[]\n",
    "for i in range(len(merged_emails)):\n",
    "    spl = []\n",
    "    try:\n",
    "        spl = merged_emails[\"SenderEmailAddress\"][i].split('@')\n",
    "    except:\n",
    "        name_email_sim.append(0)\n",
    "        continue\n",
    "    email_name = merged_emails[\"SenderEmailAddress\"][i].split('@')[0]\n",
    "    name_email_sim.append(similar(merged_emails[\"SenderName\"][i], email_name))\n",
    "\n",
    "merged_emails[\"name_email_sim\"] = name_email_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Sender email domain and URL in mail similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_emails[\"domain_url_sim\"] = [domain_url_similarity(str(merged_emails[\"domain\"][i]),str(merged_emails[\"Text\"][i])) for i in range(len(merged_emails))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get count of other keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "money_words=[\"account\",\"bank\",\"credit\",\"limit\",\"statement\",\"debit\",\"fund\",\"transaction\",\"price\",\"dollars\",\"grants\",\"insurance\",\"$\",\"dollar\"]\n",
    "identity_words=[\"account\",\"identity\",\"password\",\"user\",\"social\",\"security\",\"member\",\"email\"]\n",
    "access_words=[\"access\",\"restrict\",\"log\",\"locked\",\"login\"]\n",
    "linker_words=[\"click\",\"verify\",\"online\"]\n",
    "hook_words = [\"inconvenience\",\"update\",\"risk\",\"recently\",\"service\",\"suspension\",\"suspended\",\"confirm\",\"free\",\"win\",\"won\",\"work\",\"closed\",\"easy\",\"opportunity\"]\n",
    "maybe_words=[\"information\",\"limited\",\"minutes\",\"client\",\"hold\",\"wish\"]\n",
    "meeting_words = [\"calender invite\", \"microsoft teams meeting\", \"session\", \"meeting\", \"meeting id\", \"zoom.us\", \"webex.com\"]\n",
    "company_words = [\"microsoft\", \"gartner\", \"google\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "merged_emails[\"exclamation_count\"] = [str(doc).count('!') for doc in merged_emails.Text]\n",
    "merged_emails[\"money_count\"] = [sum(str(s).lower().count(x) for x in money_words) for s in merged_emails.Text]\n",
    "merged_emails[\"identity_count\"] = [sum(str(s).lower().count(x) for x in identity_words) for s in merged_emails.Text]\n",
    "merged_emails[\"access_count\"] = [sum(str(s).lower().count(x) for x in access_words) for s in merged_emails.Text]\n",
    "merged_emails[\"linker_count\"] = [sum(str(s).lower().count(x) for x in linker_words) for s in merged_emails.Text]\n",
    "merged_emails[\"hook_count\"] = [sum(str(s).lower().count(x) for x in hook_words) for s in merged_emails.Text]\n",
    "merged_emails[\"maybe_count\"] = [sum(str(s).lower().count(x) for x in maybe_words) for s in merged_emails.Text]\n",
    "merged_emails[\"meeting_count\"] = [sum(str(s).lower().count(x) for x in meeting_words) for s in merged_emails.Text]\n",
    "merged_emails[\"company_count\"] = [sum(str(s).lower().count(x) for x in company_words) for s in merged_emails.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "merged_emails[\"url_count\"] = [count_urls(str(doc)) for doc in merged_emails.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_emails[\"url_text_sim\"] = [text_url_similarity(str(doc)) for doc in merged_emails.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmailTo                            AksharanugrahaFra2590@ccac.sales.com\n",
       "SenderName                                      Swanback, Andrew Thomas\n",
       "SenderEmailAddress                           AbelSco2250@ccac.sales.com\n",
       "Text                  Administrative Support Opportunity Dr. Sophie ...\n",
       "Class                                                                 1\n",
       "domain                                                   ccac.sales.com\n",
       "name_email_sim                                                 0.176471\n",
       "domain_url_sim                                                        0\n",
       "exclamation_count                                                     0\n",
       "money_count                                                           1\n",
       "identity_count                                                        1\n",
       "access_count                                                          0\n",
       "linker_count                                                          0\n",
       "hook_count                                                            3\n",
       "maybe_count                                                           2\n",
       "meeting_count                                                         1\n",
       "company_count                                                         1\n",
       "url_count                                                          1054\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_emails.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# merged_emails = merged_emails.drop(columns=['url_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EmailTo', 'SenderName', 'SenderEmailAddress', 'Text', 'Class',\n",
       "       'domain', 'name_email_sim', 'domain_url_sim', 'exclamation_count',\n",
       "       'money_count', 'identity_count', 'access_count', 'linker_count',\n",
       "       'hook_count', 'maybe_count', 'meeting_count', 'company_count',\n",
       "       'url_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_emails.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "merged_emails[\"money_std\"] = minmax_scale(merged_emails[\"money_count\"])\n",
    "merged_emails[\"identity_std\"] = minmax_scale(merged_emails[\"identity_count\"])\n",
    "merged_emails[\"url_std\"] = minmax_scale(merged_emails[\"url_count\"])\n",
    "merged_emails[\"exclamation_std\"] = minmax_scale(merged_emails[\"exclamation_count\"])\n",
    "merged_emails[\"access_std\"] = minmax_scale(merged_emails[\"access_count\"])\n",
    "merged_emails[\"linker_std\"] = minmax_scale(merged_emails[\"linker_count\"])\n",
    "merged_emails[\"hook_std\"] = minmax_scale(merged_emails[\"hook_count\"])\n",
    "merged_emails[\"maybe_std\"] = minmax_scale(merged_emails[\"maybe_count\"])\n",
    "merged_emails[\"meeting_std\"] = minmax_scale(merged_emails[\"meeting_count\"])\n",
    "merged_emails[\"company_std\"] = minmax_scale(merged_emails[\"company_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly drop row from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# dropped_row_idx = random.choice(merged_emails.index)\n",
    "# merged_emails = merged_emails.drop(dropped_row_idx)\n",
    "# y_train = y_train.drop(dropped_row_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count vectorize the mail text(subject + body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 3), min_df=1, stop_words='english')\n",
    "# words = [\" \".join(doc) for doc in tokenizedMails]\n",
    "x = vectorizer.fit_transform(merged_emails.Text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append calculated columns to vectorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x=hstack(blocks=[x, np.array(merged_emails[['money_std', 'identity_std', 'url_std', 'exclamation_std','access_std', 'linker_std', 'hook_std', 'maybe_std', 'meeting_std','company_std', 'name_email_sim','domain_url_sim']])]).tocsr()\n",
    "# x = merged_emails[['money_std', 'identity_std', 'exclamation_std','access_std', 'linker_std', 'hook_std', 'maybe_std', 'meeting_std','company_std']]\n",
    "y = merged_emails.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1823x321233 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 866138 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1823, 321233)\n",
      "(782, 321233)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Predict using Metalearner</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta  (1823, 7) (1823,)\n"
     ]
    }
   ],
   "source": [
    "# get models\n",
    "models = get_models()\n",
    "# get out of fold predictions\n",
    "meta_X, meta_y = get_out_of_fold_predictions(x_train, y_train, models, True)\n",
    "print('Meta ', meta_X.shape, meta_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Fit super learner and predict accuracy on test </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/spack/gilbreth/apps/anaconda/2020.11-py38-gcc-4.8.5-djkvkvk/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Accuracy - 0.980\n",
      "\tTrain Accuracy :  0.979539641943734\n",
      "\tVal Accuracy :  0.979539641943734\n",
      "DecisionTreeClassifier: Accuracy - 0.978\n",
      "\tTrain Accuracy :  0.9782608695652174\n",
      "\tVal Accuracy :  0.9782608695652174\n",
      "MultinomialNB: Accuracy - 0.983\n",
      "\tTrain Accuracy :  0.9833759590792839\n",
      "\tVal Accuracy :  0.9833759590792839\n",
      "AdaBoostClassifier: Accuracy - 0.985\n",
      "\tTrain Accuracy :  0.9846547314578005\n",
      "\tVal Accuracy :  0.9846547314578005\n",
      "BaggingClassifier: Accuracy - 0.983\n",
      "\tTrain Accuracy :  0.9833759590792839\n",
      "\tVal Accuracy :  0.9833759590792839\n",
      "RandomForestClassifier: Accuracy - 0.978\n",
      "\tTrain Accuracy :  0.9782608695652174\n",
      "\tVal Accuracy :  0.9782608695652174\n",
      "ExtraTreesClassifier: Accuracy - 0.978\n",
      "\tTrain Accuracy :  0.9782608695652174\n",
      "\tVal Accuracy :  0.9782608695652174\n",
      "\n",
      "Super Learner: Accuracy -  0.983\n"
     ]
    }
   ],
   "source": [
    "fit_base_models(x, y, models)\n",
    "# fit the meta model\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "# evaluate base models\n",
    "evaluate_models(x_val, y_val, models)\n",
    "# evaluate meta model\n",
    "yhat,yprob = super_learner_predictions(x_val, models, meta_model)\n",
    "print()\n",
    "print('Super Learner: Accuracy -  %.3f' %(accuracy_score(y_val, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Print accuracy through each model in stacked ensemble </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Accuracy - 0.980\n",
      "\tTrain Accuracy :  0.979539641943734\n",
      "\tVal Accuracy :  0.979539641943734\n",
      "DecisionTreeClassifier: Accuracy - 0.978\n",
      "\tTrain Accuracy :  0.9782608695652174\n",
      "\tVal Accuracy :  0.9782608695652174\n",
      "MultinomialNB: Accuracy - 0.983\n",
      "\tTrain Accuracy :  0.9833759590792839\n",
      "\tVal Accuracy :  0.9833759590792839\n",
      "AdaBoostClassifier: Accuracy - 0.985\n",
      "\tTrain Accuracy :  0.9846547314578005\n",
      "\tVal Accuracy :  0.9846547314578005\n",
      "BaggingClassifier: Accuracy - 0.983\n",
      "\tTrain Accuracy :  0.9833759590792839\n",
      "\tVal Accuracy :  0.9833759590792839\n",
      "RandomForestClassifier: Accuracy - 0.978\n",
      "\tTrain Accuracy :  0.9782608695652174\n",
      "\tVal Accuracy :  0.9782608695652174\n",
      "ExtraTreesClassifier: Accuracy - 0.978\n",
      "\tTrain Accuracy :  0.9782608695652174\n",
      "\tVal Accuracy :  0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(x_val, y_val, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super Learner: Accuracy -  0.983\n"
     ]
    }
   ],
   "source": [
    "print('Super Learner: Accuracy -  %.3f' %(accuracy_score(y_val, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create test dataset for submission using CCAC and all calculated columns</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac_test = ccac_mails.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ccac_test[\"exclamation_count\"] = [str(doc).count('!') for doc in ccac_test.Text]\n",
    "ccac_test[\"exclamation_count\"] = [str(doc).count('!') for doc in ccac_test.Text]\n",
    "ccac_test[\"url_count\"] = [count_urls(str(doc)) for doc in ccac_test.Text]\n",
    "ccac_test[\"money_count\"] = [sum(str(s).lower().count(x) for x in money_words) for s in ccac_test.Text]\n",
    "ccac_test[\"identity_count\"] = [sum(str(s).lower().count(x) for x in identity_words) for s in ccac_test.Text]\n",
    "ccac_test[\"access_count\"] = [sum(str(s).lower().count(x) for x in access_words) for s in ccac_test.Text]\n",
    "ccac_test[\"linker_count\"] = [sum(str(s).lower().count(x) for x in linker_words) for s in ccac_test.Text]\n",
    "ccac_test[\"hook_count\"] = [sum(str(s).lower().count(x) for x in hook_words) for s in ccac_test.Text]\n",
    "ccac_test[\"maybe_count\"] = [sum(str(s).lower().count(x) for x in maybe_words) for s in ccac_test.Text]\n",
    "ccac_test[\"meeting_count\"] = [sum(str(s).lower().count(x) for x in meeting_words) for s in ccac_test.Text]\n",
    "ccac_test[\"company_count\"] = [sum(str(s).lower().count(x) for x in company_words) for s in ccac_test.Text]\n",
    "\n",
    "ccac_test[\"money_std\"] = minmax_scale(ccac_test[\"money_count\"])\n",
    "ccac_test[\"identity_std\"] = minmax_scale(ccac_test[\"identity_count\"])\n",
    "ccac_test[\"url_std\"] = minmax_scale(ccac_test[\"url_count\"])\n",
    "ccac_test[\"exclamation_std\"] = minmax_scale(ccac_test[\"exclamation_count\"])\n",
    "ccac_test[\"access_std\"] = minmax_scale(ccac_test[\"access_count\"])\n",
    "ccac_test[\"linker_std\"] = minmax_scale(ccac_test[\"linker_count\"])\n",
    "ccac_test[\"hook_std\"] = minmax_scale(ccac_test[\"hook_count\"])\n",
    "ccac_test[\"maybe_std\"] = minmax_scale(ccac_test[\"maybe_count\"])\n",
    "ccac_test[\"meeting_std\"] = minmax_scale(ccac_test[\"meeting_count\"])\n",
    "ccac_test[\"company_std\"] = minmax_scale(ccac_test[\"company_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "domainList=[]\n",
    "for mail in ccac_test[\"SenderEmailAddress\"]:\n",
    "    try:\n",
    "        if '@' in mail:\n",
    "            spl = mail.split('@')\n",
    "            if len(spl) > 1:\n",
    "                domainList.append(spl[1])\n",
    "            else:\n",
    "                domainList.append(\"na\")\n",
    "        else:\n",
    "            domainList.append(\"na\")\n",
    "    except:\n",
    "        domainList.append(\"na\")\n",
    "\n",
    "ccac_test[\"domain\"] = domainList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "name_email_sim=[]\n",
    "for i in range(len(ccac_test)):\n",
    "    spl = []\n",
    "    try:\n",
    "        spl = ccac_test[\"SenderEmailAddress\"][i].split('@')\n",
    "    except:\n",
    "        name_email_sim.append(0)\n",
    "        continue\n",
    "    email_name = ccac_test[\"SenderEmailAddress\"][i].split('@')[0]\n",
    "    name_email_sim.append(similar(ccac_test[\"SenderName\"][i], email_name))\n",
    "\n",
    "ccac_test[\"name_email_sim\"] = name_email_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac_test[\"domain_url_sim\"] = [domain_url_similarity(str(ccac_test[\"domain\"][i]),str(ccac_test[\"Text\"][i])) for i in range(len(ccac_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ccac_test[\"url_text_sim\"] = [text_url_similarity(str(doc)) for doc in ccac_test.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'EmailTo', 'CC', 'SenderName', 'SenderEmailAddress', 'Subject',\n",
       "       'Body', 'Text', 'exclamation_count', 'url_count', 'money_count',\n",
       "       'identity_count', 'access_count', 'linker_count', 'hook_count',\n",
       "       'maybe_count', 'meeting_count', 'company_count', 'money_std',\n",
       "       'identity_std', 'url_std', 'exclamation_std', 'access_std',\n",
       "       'linker_std', 'hook_std', 'maybe_std', 'meeting_std', 'company_std',\n",
       "       'domain', 'name_email_sim', 'domain_url_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccac_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac_x = vectorizer.transform(ccac_test.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac_x = hstack(blocks=[ccac_x, np.array(ccac_test[['money_std', 'identity_std', 'url_std', 'exclamation_std','access_std', 'linker_std', 'hook_std', 'maybe_std', 'meeting_std','company_std', 'name_email_sim','domain_url_sim']])]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4898x321233 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1659244 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccac_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ccac_x = ccac_test[['money_std', 'identity_std', 'exclamation_std','access_std', 'linker_std', 'hook_std', 'maybe_std', 'meeting_std','company_std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Predict using each model in stacked ensemble(meta learners + super learner) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "#     if model.__class__.__name__ == \"RandomForestClassifier\":\n",
    "    pred_selected = []\n",
    "    file_name =  \"sl_ccac_correctedphish_\"+str(model.__class__.__name__)+\".csv\"\n",
    "    try:\n",
    "        pred_selected = model.predict_proba(ccac_x)\n",
    "    except:\n",
    "        print(model.__class__.__name__)\n",
    "    np.savetxt(file_name, pred_selected, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "yhat,yprob = super_learner_predictions(ccac_x, models, meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"superlearner_ccac_correctedphish_.csv\", yprob, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train and predict using only Gradient Boosting model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy -  0.964\n",
      "0.9912232583653319\n",
      "0.9641943734015346\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(x_train, y_train)\n",
    "y_pred = gb_model.predict(x_val)\n",
    "print(' Accuracy -  %.3f' %(accuracy_score(y_val, y_pred)))\n",
    "print(gb_model.score(x_train,y_train))\n",
    "print(gb_model.score(x_val,y_val))\n",
    "y_gb_proba = gb_model.predict_proba(ccac_x)\n",
    "\n",
    "# np.savetxt(\"probs_gb_sampled.csv\", y_gb_proba, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"probs_gb_ccac_correctedphish.csv\", y_gb_proba, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train and predict using only Naive Bayes model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy: 96.68%\n",
      "0.9846407021393307\n",
      "0.9667519181585678\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred_nb = nb.predict(x_val)\n",
    "acc_nb = accuracy_score(y_val, y_pred_nb)\n",
    "print(\"NB Accuracy: {}%\".format(round(acc_nb*100, 2)))\n",
    "print(nb.score(x_train,y_train))\n",
    "print(nb.score(x_val,y_val))\n",
    "ccac_pred_nb_prob = nb.predict_proba(ccac_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccac_pred = nb.predict(ccac_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"probs_nb_ccac_correctedphish_.csv\", ccac_pred_nb_prob, delimiter=',')\n",
    "# np.savetxt(\"preds_nb_sub-sampled_gartner_assist_food.csv\", ccac_pred, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
